{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF-Agents-Latest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOSVAK7wfkNyxvo/QCxUCsA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/debajyotidasgupta/BTP/blob/main/TF_Agents_Latest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -U tf-agents[reverb] -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaG2kLSummCF",
        "outputId": "edf5865b-db19-43da-e0ff-6aa9825e4d90"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tf-agents[reverb]\n",
            "  Downloading tf_agents-0.11.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 3.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.11.3 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (3.10.0.2)\n",
            "Requirement already satisfied: tensorflow-probability>=0.14.1 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (0.15.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (1.19.5)\n",
            "Requirement already satisfied: gym>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (0.17.3)\n",
            "Requirement already satisfied: gin-config>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (0.5.0)\n",
            "Requirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (0.12.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (7.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (1.13.3)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (1.3.0)\n",
            "Collecting dm-reverb~=0.6.0\n",
            "  Downloading dm_reverb-0.6.1-cp37-cp37m-manylinux2010_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 20.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow~=2.7.0 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (2.7.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from dm-reverb~=0.6.0->tf-agents[reverb]) (0.1.6)\n",
            "Requirement already satisfied: portpicker in /usr/local/lib/python3.7/dist-packages (from dm-reverb~=0.6.0->tf-agents[reverb]) (1.3.9)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17.0->tf-agents[reverb]) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym>=0.17.0->tf-agents[reverb]) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.17.0->tf-agents[reverb]) (0.16.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tf-agents[reverb]) (0.22.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tf-agents[reverb]) (0.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tf-agents[reverb]) (1.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tf-agents[reverb]) (1.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tf-agents[reverb]) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tf-agents[reverb]) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tf-agents[reverb]) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tf-agents[reverb]) (2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tf-agents[reverb]) (1.42.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tf-agents[reverb]) (0.37.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tf-agents[reverb]) (2.7.0)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tf-agents[reverb]) (2.7.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tf-agents[reverb]) (12.0.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tf-agents[reverb]) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tf-agents[reverb]) (2.7.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.7.0->tf-agents[reverb]) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.7.0->tf-agents[reverb]) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.7.0->tf-agents[reverb]) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.7.0->tf-agents[reverb]) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.7.0->tf-agents[reverb]) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.7.0->tf-agents[reverb]) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.7.0->tf-agents[reverb]) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.7.0->tf-agents[reverb]) (3.3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.7.0->tf-agents[reverb]) (2.23.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow~=2.7.0->tf-agents[reverb]) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow~=2.7.0->tf-agents[reverb]) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow~=2.7.0->tf-agents[reverb]) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow~=2.7.0->tf-agents[reverb]) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow~=2.7.0->tf-agents[reverb]) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow~=2.7.0->tf-agents[reverb]) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow~=2.7.0->tf-agents[reverb]) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow~=2.7.0->tf-agents[reverb]) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow~=2.7.0->tf-agents[reverb]) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow~=2.7.0->tf-agents[reverb]) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow~=2.7.0->tf-agents[reverb]) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow~=2.7.0->tf-agents[reverb]) (3.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability>=0.14.1->tf-agents[reverb]) (4.4.2)\n",
            "Installing collected packages: tf-agents, dm-reverb\n",
            "Successfully installed dm-reverb-0.6.1 tf-agents-0.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        },
        "id": "2gng-D-gmT1n",
        "outputId": "bc2d0769-4676-4e13-b157-8d3991d58798"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xe but this version of numpy is 0xd"
          ]
        }
      ],
      "source": [
        "from copy import deepcopy\n",
        "from random import randint\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import reverb\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tf_agents.eval import metric_utils\n",
        "from tf_agents.utils import common\n",
        "from tf_agents.specs import array_spec\n",
        "from tf_agents.specs import tensor_spec\n",
        "from tf_agents.drivers import py_driver\n",
        "from tf_agents.metrics import tf_metrics\n",
        "from tf_agents.drivers import dynamic_step_driver\n",
        "from tf_agents.policies import policy_saver\n",
        "from tf_agents.policies import py_tf_eager_policy\n",
        "from tf_agents.policies import random_tf_policy\n",
        "from tf_agents.networks import sequential\n",
        "from tf_agents.agents.dqn import dqn_agent\n",
        "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
        "from tf_agents.environments import py_environment\n",
        "from tf_agents.environments import tf_environment\n",
        "from tf_agents.environments import tf_py_environment\n",
        "from tf_agents.environments import utils\n",
        "from tf_agents.environments import wrappers\n",
        "from tf_agents.environments import suite_gym\n",
        "from tf_agents.environments import gym_wrapper\n",
        "from tf_agents.trajectories import time_step as ts\n",
        "from tf_agents.replay_buffers import reverb_replay_buffer\n",
        "from tf_agents.replay_buffers import reverb_utils"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "from gym import spaces\n",
        "\n",
        "class Job:\n",
        "    def __init__(self, power, time, type_mc, name):\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        power: unit of power the process will consume,per unit time\n",
        "        time : duration of the process (in minutes)\n",
        "        '''\n",
        "        self.id = randint(1, 10**5)\n",
        "        self.name = name\n",
        "        self.power = power\n",
        "        self.type_mc = type_mc\n",
        "        self.time = time\n",
        "\n",
        "    def allocate(self, time, machine):\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        time: time to be allocated to the job\n",
        "        machine: machine to be allocated to the job\n",
        "        '''\n",
        "        self.time = time\n",
        "        self.machine = machine\n",
        "\n",
        "class SmartApplEnv(gym.Env):\n",
        "    def __init__(self, \n",
        "                 number_of_machines, # list of length same as number of different types of devices\n",
        "                 number_of_jobs,     # list of length same as number of different types of devices\n",
        "                 distinct_machines,\n",
        "                 power_rate_chart, \n",
        "                 full_day, \n",
        "                 time_per_unit,\n",
        "                 cycle_stat = None):\n",
        "      \n",
        "        self._state            = np.zeros((max(number_of_jobs), max(number_of_machines), distinct_machines))\n",
        "        self.action_space      = spaces.Discrete(1+int(pow(2, max(number_of_machines))*pow(2, distinct_machines)))\n",
        "        self.observation_space = spaces.Box(low=-1e20, high=1e20, shape=self._state.shape)\n",
        "        \n",
        "        self._episode_ended = False\n",
        "\n",
        "        # Parameters related to different data statistics\n",
        "        self.all_list         = [[] for _ in range(distinct_machines)]\n",
        "        self.job_list         = [[] for _ in range(distinct_machines)]\n",
        "        self.full_day         = full_day\n",
        "        self.time_per_unit    = time_per_unit\n",
        "        self.power_rate_chart = power_rate_chart\n",
        "\n",
        "        self.max_jobs           = number_of_jobs\n",
        "        self.max_machines       = number_of_machines\n",
        "        self.distinct_machines  = distinct_machines\n",
        "        self.number_of_jobs     = np.array(number_of_jobs    ).astype(np.int32)\n",
        "        self.number_of_machines = np.array(number_of_machines).astype(np.int32)\n",
        "\n",
        "        if cycle_stat != None:\n",
        "            for m in range(distinct_machines):\n",
        "                self.add_job(number_of_jobs[m], cycle_stat[m], m)\n",
        "        _ = self.reset()\n",
        "\n",
        "  \n",
        "    def add_machine(self, machine):\n",
        "      # correct this later\n",
        "      machine_id = self.distinct_machines\n",
        "      self.distinct_machines += 1\n",
        "      return machine_id\n",
        "    \n",
        "    def add_job(self, num_jobs, cycle_stat, machine, set_val=False):\n",
        "        # maxhine = 0 / 1 / 2 \n",
        "\n",
        "        for _ in range(num_jobs):\n",
        "            self.all_list[machine].append([])\n",
        "            self.job_list[machine].append([])\n",
        "            if set_val:\n",
        "                self.number_of_jobs[machine] += 1\n",
        "            \n",
        "            for cycle in cycle_stat:\n",
        "                self.all_list[machine][-1].append(\n",
        "                    Job(cycle['power'],\n",
        "                        (cycle['time'] + self.time_per_unit - 1) // self.time_per_unit,\n",
        "                        machine,\n",
        "                        cycle['cycle']))\n",
        "                \n",
        "                self.job_list[machine][-1].append(\n",
        "                    Job(cycle['power'],\n",
        "                        (cycle['time'] + self.time_per_unit - 1) // self.time_per_unit,\n",
        "                        machine,\n",
        "                        cycle['cycle']))\n",
        "\n",
        "\n",
        "    def amount_for_bill(self, power):\n",
        "        amount = 0\n",
        "        pos = -1\n",
        "        # Get the time of the day when the scheduling is currently being done in the power stat chart\n",
        "        for time_limit in sorted(self.power_rate_chart, reverse=True):\n",
        "            if time_limit < self.time:\n",
        "                break\n",
        "            pos = time_limit\n",
        "\n",
        "        # Get the power rate for the current time\n",
        "        amount = self.power_rate_chart[pos]['cost'] * \\\n",
        "            power * self.time_per_unit\n",
        "\n",
        "        # If the power consumption crosses the threshold, then the penalization is applied\n",
        "        if power > self.power_rate_chart[pos]['limit']:\n",
        "            amount += (power - self.power_rate_chart[pos]['limit']) * \\\n",
        "                self.power_rate_chart[pos]['penalty'] * self.time_per_unit\n",
        "        return amount\n",
        "\n",
        "    def generate_state_encoding(self):\n",
        "        MN, MX = -300, 0\n",
        "        image = np.zeros(self._state.shape, dtype=np.float32)\n",
        "\n",
        "        pos = -1\n",
        "        # Get the time of the day when the scheduling is currently being done in the power stat chart\n",
        "        for time_limit in sorted(self.power_rate_chart, reverse=True):\n",
        "            if time_limit < self.time:\n",
        "                break\n",
        "            pos = time_limit\n",
        "\n",
        "        for m in range(self.distinct_machines):\n",
        "            for i in range(self.number_of_jobs[m]):\n",
        "                for j in range(self.number_of_machines[m]):\n",
        "                    if self.machine_free_time[m, j] <= self.time\\\n",
        "                            and self.job_free_time[m, i] <= self.time\\\n",
        "                            and (self.job_allocation_list[m, i] == -1 or\n",
        "                                self.job_allocation_list[m, i] == j)\\\n",
        "                            and (self.machine_allocation_list[m, j] == -1 or\n",
        "                                self.machine_allocation_list[m, j] == i)\\\n",
        "                            and len(self.job_list[m][i]) > 0:\n",
        "\n",
        "                        image[i, j, m] = self.job_list[m][i][0].power -\\\n",
        "                            self.power_rate_chart[pos]['limit']\n",
        "                        #another idea can be to use the get_cost  method\n",
        "\n",
        "                        MX = max(MX, image[i, j, m])\n",
        "                    else:\n",
        "                        image[i, j, m] = MN\n",
        "        # plt.imshow(image, cmap=\"hot\")\n",
        "        return image / max(1, MX)  # changed this line\n",
        "\n",
        "    def reset(self):\n",
        "        # Make the job list from the data of the cycles on machines\n",
        "        self.job_list = deepcopy(self.all_list)\n",
        "\n",
        "        # parameters describing the state of the environment\n",
        "        self.time = 0\n",
        "        self.machine_free_time       = np.zeros((self.distinct_machines, np.max(self.number_of_machines)), dtype=np.int32)\n",
        "        self.job_free_time           = np.zeros((self.distinct_machines, np.max(self.number_of_jobs)),     dtype=np.int32)\n",
        "        self.machine_allocation_list = np.zeros((self.distinct_machines, np.max(self.number_of_machines)), dtype=np.int32) - 1\n",
        "        self.job_allocation_list     = np.zeros((self.distinct_machines, np.max(self.number_of_jobs)),     dtype=np.int32) - 1\n",
        "\n",
        "        self.bill = 0\n",
        "        self._state = self.generate_state_encoding()\n",
        "        self._episode_ended = False\n",
        "        # print(self._state.shape)\n",
        "        return self._state\n",
        "\n",
        "    def schedule(self, machine, action):\n",
        "        power, reward = 0, 0\n",
        "\n",
        "        for m in range(self.distinct_machines):\n",
        "            for i in range(self.number_of_machines[m]):\n",
        "                if action & (1 << i):\n",
        "                    if self.machine_free_time[m, i] <= self.time:\n",
        "                        if self.machine_allocation_list[m, i] == -1:\n",
        "                            for j in range(self.number_of_jobs[m]):\n",
        "                                if self.job_free_time[m, j] == 0:\n",
        "                                    self.machine_allocation_list[m, i] = j\n",
        "                                    self.job_allocation_list[m, j] = i\n",
        "\n",
        "                                    reward += 20000.\n",
        "                                    break\n",
        "\n",
        "                        job = self.machine_allocation_list[m, i]\n",
        "                        if job == -1:\n",
        "                            continue\n",
        "\n",
        "                        self.job_free_time[m, job] += self.job_list[m][job][0].time\n",
        "                        self.machine_free_time[m, i] += self.job_list[m][job][0].time\n",
        "                        power += self.job_list[m][job][0].power\n",
        "\n",
        "                        reward += 10000. * self.job_list[m][job][0].time\n",
        "                        self.job_list[m][job].pop(0)\n",
        "\n",
        "                        if len(self.job_list[m][job]) == 0:\n",
        "                            reward += 500000.\n",
        "                            self.machine_allocation_list[m, i] = -1\n",
        "                            self.job_allocation_list[m, job] = -1\n",
        "                    else:\n",
        "                        reward -= 1500.\n",
        "        return power, reward\n",
        "\n",
        "\n",
        "    def step(self, action):\n",
        "        if self._episode_ended:\n",
        "            return self.reset()\n",
        "\n",
        "        # actions += 1\n",
        "        reward, done, info = -100., False, {} # make 10. -> 100.\n",
        "        power = 0\n",
        "\n",
        "\n",
        "        for machine in range(self.distinct_machines):\n",
        "            if action < self.action_space.n - 1:\n",
        "                mask   = action % int(pow(2, self.number_of_machines[machine]))\n",
        "                action = action // int(pow(2, self.number_of_machines[machine]))\n",
        "                cur_pow, cur_rew = self.schedule(machine, mask)\n",
        "                power  += cur_pow\n",
        "                reward += cur_rew\n",
        "            \n",
        "            for i in self.job_list[machine]:\n",
        "                reward -= len(i) * 100.  # make this 1000.\n",
        "\n",
        "        reward -= self.amount_for_bill(power) * 100\n",
        "        self.bill += self.amount_for_bill(power)\n",
        "\n",
        "        self.time += 1\n",
        "        if self.time == self.full_day:\n",
        "            done = True\n",
        "        \n",
        "        self._state = self.generate_state_encoding()\n",
        "        self._episode_ended = done\n",
        "        info = {}\n",
        "\n",
        "        return self._state, reward, self._episode_ended, info\n",
        "    \n",
        "    def render(self, args):\n",
        "        fig, ax = plt.subplots(1, 3, figsize=(5, 5))\n",
        "        for i in range(self._state.shape[2]):\n",
        "            ax[i].imshow(self._state[:,:,i])\n",
        "            ax[i].grid(False)"
      ],
      "metadata": {
        "id": "7HeKgdLrmWxN"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "power = {\n",
        "    240:  {\"cost\": 10,\"limit\": 110,\"penalty\": 450},\n",
        "    480:  {\"cost\": 30,\"limit\": 110,\"penalty\": 290},\n",
        "    720:  {\"cost\": 80,\"limit\": 200,\"penalty\": 50},\n",
        "    960:  {\"cost\": 45,\"limit\": 170,\"penalty\": 180},\n",
        "    1200: {\"cost\": 20,\"limit\": 140,\"penalty\": 380},\n",
        "    1440: {\"cost\": 5,\"limit\": 230,\"penalty\": 550}\n",
        "}\n",
        "\n",
        "\n",
        "machine1 = [\n",
        "    {\"cycle\": \"Water Fill\", \"power\": 0,      \"time\": 10},\n",
        "    {\"cycle\": \"Agitation\",  \"power\": 3.97,   \"time\": 10},\n",
        "    {\"cycle\": \"Wash\",       \"power\": 70.05,  \"time\": 15},\n",
        "    {\"cycle\": \"Drain\",      \"power\": 0,      \"time\": 5},\n",
        "    {\"cycle\": \"Spin\",       \"power\": 11.53,  \"time\": 5},\n",
        "    {\"cycle\": \"Water Fill\", \"power\": 0,      \"time\": 10},\n",
        "    {\"cycle\": \"Rinse\",      \"power\": 21.14,  \"time\": 5},\n",
        "    {\"cycle\": \"Drain\",      \"power\": 0,      \"time\": 5},\n",
        "    {\"cycle\": \"Spin\",       \"power\": 28.09,  \"time\": 10}\n",
        "]\n",
        "machine2 = [{\"cycle\": \"microwave\",\"power\": 50,\"time\" : 10,}]\n",
        "machine3 = [{\"cycle\": \"AC\",\"power\": 100,\"time\" : 25,}]"
      ],
      "metadata": {
        "id": "JP98UiommYlE"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hyperparameters"
      ],
      "metadata": {
        "id": "z59PEQoEopOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N_MACHINES = [7,7,7]\n",
        "N_JOBS = [40,40,40]\n",
        "UNIT = 5\n",
        "TIME = 2000\n",
        "VISUALIZE = False\n",
        "\n",
        "num_iterations = 20000 # @param {type:\"integer\"}\n",
        "\n",
        "initial_collect_steps = 1000  # @param {type:\"integer\"}\n",
        "collect_steps_per_iteration =   1# @param {type:\"integer\"}\n",
        "replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
        "\n",
        "batch_size = 64  # @param {type:\"integer\"}\n",
        "learning_rate = 1e-3  # @param {type:\"number\"}\n",
        "log_interval = 200  # @param {type:\"integer\"}\n",
        "\n",
        "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
        "eval_interval = 1000  # @param {type:\"integer\"}"
      ],
      "metadata": {
        "id": "VR1vZORlmauk"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Environment"
      ],
      "metadata": {
        "id": "Un5Ff_fjot3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gym_env = SmartApplEnv(number_of_machines=N_MACHINES,\n",
        "                   number_of_jobs=N_JOBS,\n",
        "                   distinct_machines=3,\n",
        "                   power_rate_chart=power,\n",
        "                   full_day= TIME // UNIT,\n",
        "                   time_per_unit=UNIT,\n",
        "                   cycle_stat = [machine1, machine2, machine3]\n",
        "                  )"
      ],
      "metadata": {
        "id": "XKkzjBchmcOd"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "py_env = gym_wrapper.GymWrapper(gym_env)\n",
        "tf_env = tf_py_environment.TFPyEnvironment(py_env)"
      ],
      "metadata": {
        "id": "1_UD4EvTmeBW"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Agent"
      ],
      "metadata": {
        "id": "Xn-1uR27oior"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "action_tensor_spec = tensor_spec.from_spec(py_env.action_spec())\n",
        "num_actions = action_tensor_spec.maximum - action_tensor_spec.minimum + 1\n",
        "\n",
        "layers = [\n",
        "    tf.keras.layers.Conv2D(128,  (3, 3), padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(padding='same'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(128, (1, 1), padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(padding='same'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(64,  (3, 3), padding='same', activation='relu'),\n",
        "    tf.keras.layers.AvgPool2D(padding='same'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(32,  (3, 3), padding='same', activation='relu'),\n",
        "    tf.keras.layers.AvgPool2D(padding='same'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(256, activation='relu', kernel_initializer=tf.keras.initializers.VarianceScaling(scale=2.0, mode='fan_in', distribution='truncated_normal')),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(32, activation='relu', kernel_initializer=tf.keras.initializers.VarianceScaling(scale=2.0, mode='fan_in', distribution='truncated_normal')),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(8,  activation='relu', kernel_initializer=tf.keras.initializers.VarianceScaling(scale=2.0, mode='fan_in', distribution='truncated_normal')),\n",
        "    tf.keras.layers.Dropout(0.2)\n",
        "]\n",
        "\n",
        "q_values_layer = tf.keras.layers.Dense(num_actions, activation=None, kernel_initializer=tf.keras.initializers.RandomUniform(minval=-0.03, maxval=0.03), bias_initializer=tf.keras.initializers.Constant(-0.2))\n",
        "q_net = sequential.Sequential(layers + [q_values_layer])"
      ],
      "metadata": {
        "id": "o_HYhyIKmjsk"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "update_period = 4 # train the model every 4 steps\n",
        "optimizer = tf.keras.optimizers.RMSprop(learning_rate=2.5e-4, rho=0.95, momentum=0.0, epsilon=0.00001, centered=True)\n",
        "train_step_counter = tf.Variable(0)\n",
        "\n",
        "# epsilon_fn = tf.keras.optimizers.schedules.PolynomialDecay(\n",
        "#     initial_learning_rate=1.0, # initial ε\n",
        "#     decay_steps=num_iterations // update_period, # <=> 1,000,000 ALE frames\n",
        "#     end_learning_rate=0.01) # final ε\n",
        "\n",
        "agent = dqn_agent.DqnAgent(\n",
        "    tf_env.time_step_spec(),\n",
        "    tf_env.action_spec(),\n",
        "    q_network=q_net,\n",
        "    optimizer=optimizer,\n",
        "    debug_summaries = True,\n",
        "    summarize_grads_and_vars = True,\n",
        "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
        "    train_step_counter=train_step_counter,\n",
        "    # epsilon_greedy=lambda: epsilon_fn(train_step_counter),\n",
        ")\n",
        "\n",
        "agent.initialize()"
      ],
      "metadata": {
        "id": "tHSfFCHxmy5-"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q_net.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chBPR14_pqNs",
        "outputId": "e10a2156-fad2-402c-ad82-6e2746dbdc82"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_14 (Conv2D)           multiple                  3584      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 multiple                  0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc multiple                  512       \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           multiple                  16512     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 multiple                  0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc multiple                  512       \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           multiple                  73792     \n",
            "_________________________________________________________________\n",
            "average_pooling2d_6 (Average multiple                  0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc multiple                  256       \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           multiple                  18464     \n",
            "_________________________________________________________________\n",
            "average_pooling2d_7 (Average multiple                  0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc multiple                  128       \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             multiple                  24832     \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             multiple                  8224      \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             multiple                  264       \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             multiple                  9225      \n",
            "=================================================================\n",
            "Total params: 156,305\n",
            "Trainable params: 155,601\n",
            "Non-trainable params: 704\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Policies"
      ],
      "metadata": {
        "id": "jB45wn41ozXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_policy = agent.policy\n",
        "collect_policy = agent.collect_policy"
      ],
      "metadata": {
        "id": "3KSe87T9m2BL"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_policy = random_tf_policy.RandomTFPolicy(tf_env.time_step_spec(),\n",
        "                                                tf_env.action_spec())\n",
        "time_step = tf_env.reset()\n",
        "random_policy.action(time_step)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8AHIeNGnd95",
        "outputId": "bbceaa25-221e-4ab6-d403-f617a27bc348"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([246])>, state=(), info=())"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Metrics and Evaluation"
      ],
      "metadata": {
        "id": "W0l84Hl0o65F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_min_avg_return(environment, python_env, policy, num_episodes=10):\n",
        "  total_return = 0.0\n",
        "  min_bill = float('inf')\n",
        "\n",
        "  for _ in range(num_episodes):\n",
        "\n",
        "    time_step = environment.reset()\n",
        "    episode_return = 0.0\n",
        "\n",
        "    while not time_step.is_last():\n",
        "      action_step = policy.action(time_step)\n",
        "      time_step = environment.step(action_step.action)\n",
        "      episode_return += time_step.reward\n",
        "    total_return += episode_return\n",
        "    min_bill = min(min_bill, python_env.bill)\n",
        "\n",
        "  avg_return = total_return / num_episodes\n",
        "  return avg_return.numpy()[0], min_bill"
      ],
      "metadata": {
        "id": "wGfq5VDVngpE"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute_min_avg_return(tf_env, py_env, random_policy, num_eval_episodes)\n",
        "# print('\\n',py_env.bill)\n",
        "# print([len(i) for i in py_env.job_list[0]])\n",
        "# print([len(i) for i in py_env.job_list[1]])\n",
        "# print([len(i) for i in py_env.job_list[2]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_5O3o3Ao9gd",
        "outputId": "6957d56f-a84c-4e12-d5d4-54a750a25bed"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-1218078600.0, 12157307.5)"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Replay Buffer"
      ],
      "metadata": {
        "id": "PaiaQQ5rp_0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "table_name = 'uniform_table'\n",
        "replay_buffer_signature = tensor_spec.from_spec(\n",
        "      agent.collect_data_spec)\n",
        "replay_buffer_signature = tensor_spec.add_outer_dim(\n",
        "    replay_buffer_signature)\n",
        "\n",
        "table = reverb.Table(\n",
        "    table_name,\n",
        "    max_size=replay_buffer_max_length,\n",
        "    sampler=reverb.selectors.Uniform(),\n",
        "    remover=reverb.selectors.Fifo(),\n",
        "    rate_limiter=reverb.rate_limiters.MinSize(1),\n",
        "    signature=replay_buffer_signature)\n",
        "\n",
        "reverb_server = reverb.Server([table])\n",
        "\n",
        "replay_buffer = reverb_replay_buffer.ReverbReplayBuffer(\n",
        "    agent.collect_data_spec,\n",
        "    table_name=table_name,\n",
        "    sequence_length=2,\n",
        "    local_server=reverb_server)\n",
        "\n",
        "rb_observer = reverb_utils.ReverbAddTrajectoryObserver(\n",
        "  replay_buffer.py_client,\n",
        "  table_name,\n",
        "  sequence_length=2)"
      ],
      "metadata": {
        "id": "0U8DsHaOpJLl"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Collection\n",
        "\n"
      ],
      "metadata": {
        "id": "uVEK2xS3r24k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "py_driver.PyDriver(\n",
        "    py_env,\n",
        "    py_tf_eager_policy.PyTFEagerPolicy(\n",
        "      random_policy, use_tf_function=True),\n",
        "    [rb_observer],\n",
        "    max_steps=initial_collect_steps).run(py_env.reset())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXLL87M-Yhmw",
        "outputId": "1ec9086d-6715-4d2e-eeca-2b9f4c7b9886"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TimeStep(\n",
              "{'discount': array(1., dtype=float32),\n",
              " 'observation': array([[[-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ]],\n",
              "\n",
              "       [[-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ]],\n",
              "\n",
              "       [[-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ]],\n",
              "\n",
              "       [[-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ]],\n",
              "\n",
              "       [[-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ]],\n",
              "\n",
              "       [[-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ]],\n",
              "\n",
              "       [[-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ]],\n",
              "\n",
              "       [[-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ]],\n",
              "\n",
              "       [[-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ]],\n",
              "\n",
              "       [[-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ]],\n",
              "\n",
              "       [[-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ]],\n",
              "\n",
              "       [[-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ]],\n",
              "\n",
              "       [[-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ]],\n",
              "\n",
              "       [[-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ]],\n",
              "\n",
              "       [[-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ]],\n",
              "\n",
              "       [[-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ]],\n",
              "\n",
              "       [[-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ]],\n",
              "\n",
              "       [[-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ]],\n",
              "\n",
              "       [[-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ]],\n",
              "\n",
              "       [[-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ]],\n",
              "\n",
              "       [[-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ]],\n",
              "\n",
              "       [[-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ]],\n",
              "\n",
              "       [[-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ]],\n",
              "\n",
              "       [[-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ]],\n",
              "\n",
              "       [[-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ]],\n",
              "\n",
              "       [[-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ]],\n",
              "\n",
              "       [[-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ]],\n",
              "\n",
              "       [[-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ]],\n",
              "\n",
              "       [[-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ]],\n",
              "\n",
              "       [[-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ]],\n",
              "\n",
              "       [[-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ]],\n",
              "\n",
              "       [[-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ]],\n",
              "\n",
              "       [[-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ]],\n",
              "\n",
              "       [[-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ]],\n",
              "\n",
              "       [[-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ]],\n",
              "\n",
              "       [[-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ]],\n",
              "\n",
              "       [[-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ]],\n",
              "\n",
              "       [[-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ]],\n",
              "\n",
              "       [[-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [ -81.91, -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ]],\n",
              "\n",
              "       [[-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-110.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ],\n",
              "        [-300.  , -300.  , -300.  ]]], dtype=float32),\n",
              " 'reward': array(-600., dtype=float32),\n",
              " 'step_type': array(1, dtype=int32)}),\n",
              " ())"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset generates trajectories with shape [Bx2x...]\n",
        "dataset = replay_buffer.as_dataset(\n",
        "    num_parallel_calls=3,\n",
        "    sample_batch_size=batch_size,\n",
        "    num_steps=2).prefetch(3)\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-z-m0OzdaDQA",
        "outputId": "07e6f5d6-7385-4c19-c6ca-3b1725af6fe7"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: (Trajectory(\n",
              "{action: (64, 2),\n",
              " discount: (64, 2),\n",
              " next_step_type: (64, 2),\n",
              " observation: (64, 2, 40, 7, 3),\n",
              " policy_info: (),\n",
              " reward: (64, 2),\n",
              " step_type: (64, 2)}), SampleInfo(key=(64, 2), probability=(64, 2), table_size=(64, 2), priority=(64, 2))), types: (Trajectory(\n",
              "{action: tf.int64,\n",
              " discount: tf.float32,\n",
              " next_step_type: tf.int32,\n",
              " observation: tf.float32,\n",
              " policy_info: (),\n",
              " reward: tf.float32,\n",
              " step_type: tf.int32}), SampleInfo(key=tf.uint64, probability=tf.float64, table_size=tf.int64, priority=tf.float64))>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iterator = iter(dataset)\n",
        "print(iterator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIqt1JSLaoFf",
        "outputId": "5a0ac929-96ff-4836-8c2a-cc7248370d15"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7fad38327ed0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  %%time\n",
        "except:\n",
        "  pass\n",
        "\n",
        "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
        "agent.train = common.function(agent.train)\n",
        "\n",
        "# Reset the train step.\n",
        "agent.train_step_counter.assign(0)\n",
        "\n",
        "# Evaluate the agent's policy once before training.\n",
        "avg_return, min_bill = compute_min_avg_return(tf_env, py_env, agent.policy, num_eval_episodes)\n",
        "returns = [(avg_return, min_bill)]\n",
        "\n",
        "# Reset the environment.\n",
        "time_step = py_env.reset()\n",
        "\n",
        "# Create a driver to collect experience.\n",
        "collect_driver = py_driver.PyDriver(\n",
        "    py_env,\n",
        "    py_tf_eager_policy.PyTFEagerPolicy(\n",
        "      agent.collect_policy, use_tf_function=True),\n",
        "    [rb_observer],\n",
        "    max_steps=collect_steps_per_iteration)\n",
        "\n",
        "max_reward = float('-inf')\n",
        "tf_policy_saver = policy_saver.PolicySaver(agent.policy, batch_size=None)\n",
        "\n",
        "for it in range(num_iterations):\n",
        "\n",
        "  # Collect a few steps and save to the replay buffer.\n",
        "  time_step, _ = collect_driver.run(time_step)\n",
        "\n",
        "  # Sample a batch of data from the buffer and update the agent's network.\n",
        "  experience, unused_info = next(iterator)\n",
        "  train_loss = agent.train(experience).loss\n",
        "\n",
        "  step = agent.train_step_counter.numpy()\n",
        "\n",
        "  if step % log_interval == 0:\n",
        "    print('step = {0}: loss = {1}'.format(step, train_loss))\n",
        "\n",
        "  if step % eval_interval == 0:\n",
        "    avg_return, min_bill = compute_min_avg_return(tf_env, py_env, agent.policy, num_eval_episodes)\n",
        "    print('step = {0}: Average Return = {1}, Minimum Bill = {2}\\n'.format(step, avg_return, min_bill))\n",
        "    returns.append((avg_return, min_bill))\n",
        "\n",
        "    if avg_return > max_reward:\n",
        "      max_reward = avg_return\n",
        "      policy = agent.collect_policy\n",
        "      tf_policy_saver.save(f'policy_{it+1}')\n",
        "      print(f\"Saved Model at [policy_{it+1}]\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvWtthI8awiV",
        "outputId": "84689201-0e2c-41d3-b0df-fa4c40de58d4"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 0 ns, sys: 13 µs, total: 13 µs\n",
            "Wall time: 25.5 µs\n",
            "step = 200: loss = 203645421355008.0\n",
            "step = 400: loss = 697282169143296.0\n",
            "step = 600: loss = 75752150138880.0\n",
            "step = 800: loss = 14799461154816.0\n",
            "step = 1000: loss = 336446934220800.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation with unsupported characters which will be renamed to step_type, reward, discount, observation in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 1000: Average Return = -1304895488.0, Minimum Bill = 13714498.5\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as sequential_4_layer_call_fn, sequential_4_layer_call_and_return_conditional_losses, sequential_4_layer_call_fn, sequential_4_layer_call_and_return_conditional_losses, sequential_4_layer_call_and_return_conditional_losses while saving (showing 5 of 65). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: policy_999/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:561: UserWarning: Encoding a StructuredValue with type tf_agents.policies.greedy_policy.DeterministicWithLogProb_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  \"imported and registered.\" % type_spec_class_name)\n",
            "INFO:tensorflow:Assets written to: policy_999/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved Model at [policy_999]\n",
            "\n",
            "step = 1200: loss = 136514746974208.0\n",
            "step = 1400: loss = 154887744651264.0\n",
            "step = 1600: loss = 229225407709184.0\n",
            "step = 1800: loss = 489555304120320.0\n",
            "step = 2000: loss = 175451930624000.0\n",
            "step = 2000: Average Return = -1471595648.0, Minimum Bill = 15381241.5\n",
            "\n",
            "step = 2200: loss = 196406102982656.0\n",
            "step = 2400: loss = 59328513966080.0\n",
            "step = 2600: loss = 185508344889344.0\n",
            "step = 2800: loss = 348577666695168.0\n",
            "step = 3000: loss = 260550265143296.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation with unsupported characters which will be renamed to step_type, reward, discount, observation in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 3000: Average Return = -1084391808.0, Minimum Bill = 11487482.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as sequential_4_layer_call_fn, sequential_4_layer_call_and_return_conditional_losses, sequential_4_layer_call_fn, sequential_4_layer_call_and_return_conditional_losses, sequential_4_layer_call_and_return_conditional_losses while saving (showing 5 of 65). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: policy_2999/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:561: UserWarning: Encoding a StructuredValue with type tf_agents.policies.greedy_policy.DeterministicWithLogProb_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  \"imported and registered.\" % type_spec_class_name)\n",
            "INFO:tensorflow:Assets written to: policy_2999/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved Model at [policy_2999]\n",
            "\n",
            "step = 3200: loss = 591626577641472.0\n",
            "step = 3400: loss = 35331302752256.0\n",
            "step = 3600: loss = 125163358126080.0\n",
            "step = 3800: loss = 160120541544448.0\n",
            "step = 4000: loss = 669541109596160.0\n",
            "step = 4000: Average Return = -1521934592.0, Minimum Bill = 15899035.0\n",
            "\n",
            "step = 4200: loss = 297547415420928.0\n",
            "step = 4400: loss = 686466434859008.0\n",
            "step = 4600: loss = 487155960905728.0\n",
            "step = 4800: loss = 185847143989248.0\n",
            "step = 5000: loss = 344327528120320.0\n",
            "step = 5000: Average Return = -1521934592.0, Minimum Bill = 15899035.0\n",
            "\n",
            "step = 5200: loss = 270489289228288.0\n",
            "step = 5400: loss = 572623629058048.0\n",
            "step = 5600: loss = 307129755893760.0\n",
            "step = 5800: loss = 844340372963328.0\n",
            "step = 6000: loss = 789353987047424.0\n",
            "step = 6000: Average Return = -1522173568.0, Minimum Bill = 15899035.0\n",
            "\n",
            "step = 6200: loss = 218859286036480.0\n",
            "step = 6400: loss = 119605343289344.0\n",
            "step = 6600: loss = 483029000650752.0\n",
            "step = 6800: loss = 188659156385792.0\n",
            "step = 7000: loss = 466318893514752.0\n",
            "step = 7000: Average Return = -1320761088.0, Minimum Bill = 13884160.0\n",
            "\n",
            "step = 7200: loss = 256846711488512.0\n",
            "step = 7400: loss = 328234755424256.0\n",
            "step = 7600: loss = 66042780975104.0\n",
            "step = 7800: loss = 136119442210816.0\n",
            "step = 8000: loss = 158051222945792.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation with unsupported characters which will be renamed to step_type, reward, discount, observation in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 8000: Average Return = -1061035648.0, Minimum Bill = 11262482.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as sequential_4_layer_call_fn, sequential_4_layer_call_and_return_conditional_losses, sequential_4_layer_call_fn, sequential_4_layer_call_and_return_conditional_losses, sequential_4_layer_call_and_return_conditional_losses while saving (showing 5 of 65). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: policy_7999/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:561: UserWarning: Encoding a StructuredValue with type tf_agents.policies.greedy_policy.DeterministicWithLogProb_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  \"imported and registered.\" % type_spec_class_name)\n",
            "INFO:tensorflow:Assets written to: policy_7999/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved Model at [policy_7999]\n",
            "\n",
            "step = 8200: loss = 233508463181824.0\n",
            "step = 8400: loss = 113016595021824.0\n",
            "step = 8600: loss = 117058092138496.0\n",
            "step = 8800: loss = 155510145810432.0\n",
            "step = 9000: loss = 297424673308672.0\n",
            "step = 9000: Average Return = -1646751872.0, Minimum Bill = 17151250.0\n",
            "\n",
            "step = 9200: loss = 28767374278656.0\n",
            "step = 9400: loss = 170232891047936.0\n",
            "step = 9600: loss = 305712953556992.0\n",
            "step = 9800: loss = 111621552734208.0\n",
            "step = 10000: loss = 25349607915520.0\n",
            "step = 10000: Average Return = -1521677440.0, Minimum Bill = 15899035.0\n",
            "\n",
            "step = 10200: loss = 51341435076608.0\n",
            "step = 10400: loss = 477583082782720.0\n",
            "step = 10600: loss = 47425653833728.0\n",
            "step = 10800: loss = 96919024041984.0\n",
            "step = 11000: loss = 449630194106368.0\n",
            "step = 11000: Average Return = -1305472000.0, Minimum Bill = 13718199.5\n",
            "\n",
            "step = 11200: loss = 285123215884288.0\n",
            "step = 11400: loss = 931893348401152.0\n",
            "step = 11600: loss = 86521512198144.0\n",
            "step = 11800: loss = 909550458765312.0\n",
            "step = 12000: loss = 268573129834496.0\n",
            "step = 12000: Average Return = -1406074112.0, Minimum Bill = 14738385.5\n",
            "\n",
            "step = 12200: loss = 45274189791232.0\n",
            "step = 12400: loss = 611539522420736.0\n",
            "step = 12600: loss = 62240015253504.0\n",
            "step = 12800: loss = 81065695772672.0\n",
            "step = 13000: loss = 511546073546752.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation with unsupported characters which will be renamed to step_type, reward, discount, observation in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 13000: Average Return = -997918336.0, Minimum Bill = 10640616.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as sequential_4_layer_call_fn, sequential_4_layer_call_and_return_conditional_losses, sequential_4_layer_call_fn, sequential_4_layer_call_and_return_conditional_losses, sequential_4_layer_call_and_return_conditional_losses while saving (showing 5 of 65). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: policy_12999/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:561: UserWarning: Encoding a StructuredValue with type tf_agents.policies.greedy_policy.DeterministicWithLogProb_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  \"imported and registered.\" % type_spec_class_name)\n",
            "INFO:tensorflow:Assets written to: policy_12999/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved Model at [policy_12999]\n",
            "\n",
            "step = 13200: loss = 619982421491712.0\n",
            "step = 13400: loss = 28526010957824.0\n",
            "step = 13600: loss = 774552724439040.0\n",
            "step = 13800: loss = 71733872689152.0\n",
            "step = 14000: loss = 291968856883200.0\n",
            "step = 14000: Average Return = -1463707776.0, Minimum Bill = 15308409.5\n",
            "\n",
            "step = 14200: loss = 156760736268288.0\n",
            "step = 14400: loss = 60864661028864.0\n",
            "step = 14600: loss = 119684280090624.0\n",
            "step = 14800: loss = 64685361594368.0\n",
            "step = 15000: loss = 165475963109376.0\n",
            "step = 15000: Average Return = -1034460032.0, Minimum Bill = 11001736.5\n",
            "\n",
            "step = 15200: loss = 585265865293824.0\n",
            "step = 15400: loss = 186269443293184.0\n",
            "step = 15600: loss = 317087201361920.0\n",
            "step = 15800: loss = 60608590381056.0\n",
            "step = 16000: loss = 186231258349568.0\n",
            "step = 16000: Average Return = -1069130880.0, Minimum Bill = 11349568.5\n",
            "\n",
            "step = 16200: loss = 63479918624768.0\n",
            "step = 16400: loss = 218841418301440.0\n",
            "step = 16600: loss = 251869632921600.0\n",
            "step = 16800: loss = 626067853279232.0\n",
            "step = 17000: loss = 243786923900928.0\n",
            "step = 17000: Average Return = -1521927936.0, Minimum Bill = 15899035.0\n",
            "\n",
            "step = 17200: loss = 87072979288064.0\n",
            "step = 17400: loss = 27048953249792.0\n",
            "step = 17600: loss = 10809413468160.0\n",
            "step = 17800: loss = 43689657237504.0\n",
            "step = 18000: loss = 35362688729088.0\n",
            "step = 18000: Average Return = -1353291648.0, Minimum Bill = 14210687.0\n",
            "\n",
            "step = 18200: loss = 500108038766592.0\n",
            "step = 18400: loss = 307751519518720.0\n",
            "step = 18600: loss = 52872775467008.0\n",
            "step = 18800: loss = 8997386059776.0\n",
            "step = 19000: loss = 23886051672064.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation with unsupported characters which will be renamed to step_type, reward, discount, observation in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 19000: Average Return = -955398528.0, Minimum Bill = 10206811.5\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as sequential_4_layer_call_fn, sequential_4_layer_call_and_return_conditional_losses, sequential_4_layer_call_fn, sequential_4_layer_call_and_return_conditional_losses, sequential_4_layer_call_and_return_conditional_losses while saving (showing 5 of 65). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: policy_18999/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:561: UserWarning: Encoding a StructuredValue with type tf_agents.policies.greedy_policy.DeterministicWithLogProb_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  \"imported and registered.\" % type_spec_class_name)\n",
            "INFO:tensorflow:Assets written to: policy_18999/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved Model at [policy_18999]\n",
            "\n",
            "step = 19200: loss = 126013870702592.0\n",
            "step = 19400: loss = 37104239247360.0\n",
            "step = 19600: loss = 411200638681088.0\n",
            "step = 19800: loss = 7801705550839808.0\n",
            "step = 20000: loss = 53423655354368.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation with unsupported characters which will be renamed to step_type, reward, discount, observation in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 20000: Average Return = -918684032.0, Minimum Bill = 9848829.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as sequential_4_layer_call_fn, sequential_4_layer_call_and_return_conditional_losses, sequential_4_layer_call_fn, sequential_4_layer_call_and_return_conditional_losses, sequential_4_layer_call_and_return_conditional_losses while saving (showing 5 of 65). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: policy_19999/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:561: UserWarning: Encoding a StructuredValue with type tf_agents.policies.greedy_policy.DeterministicWithLogProb_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  \"imported and registered.\" % type_spec_class_name)\n",
            "INFO:tensorflow:Assets written to: policy_19999/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved Model at [policy_19999]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iterations = range(0, num_iterations + 1, eval_interval)\n",
        "\n",
        "plt.subplots_adjust(wspace = 1.7)\n",
        "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "avg = [i[0] for i in returns]\n",
        "mnm = [i[1] for i in returns]  \n",
        "\n",
        "for i in range(1, len(avg)): avg[i] = max(avg[i-1], avg[i])\n",
        "for i in range(1, len(mnm)): mnm[i] = min(mnm[i-1], mnm[i])\n",
        "\n",
        "ax[0].plot(iterations, avg)\n",
        "ax[1].plot(iterations, mnm)\n",
        "\n",
        "ax[0].set_ylabel('Average Return')\n",
        "ax[1].set_ylabel('Minimum Bill')\n",
        "\n",
        "ax[0].set_xlabel('Iterations')\n",
        "ax[1].set_xlabel('Iterations')\n",
        "\n",
        "# ax[0].set_ylim(top=250)\n",
        "# ax[0].set_ylim(top=250)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "7xF4dT0tvk2b",
        "outputId": "44e9cf4e-a3b5-4047-8dbf-d6cd735476ab"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Iterations')"
            ]
          },
          "metadata": {},
          "execution_count": 113
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saved_policy = tf.saved_model.load('policy_19999')\n",
        "\n",
        "time_step = tf_env.reset()\n",
        "while not time_step.is_last():\n",
        "  action_step = saved_policy.action(time_step)\n",
        "  time_step = tf_env.step(action_step.action)\n",
        "\n",
        "print(py_env.bill)\n",
        "print([len(i) for i in py_env.job_list[0]])\n",
        "print([len(i) for i in py_env.job_list[1]])\n",
        "print([len(i) for i in py_env.job_list[2]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdkaimUziuh2",
        "outputId": "29084aca-f73c-465e-f126-9d0c1c243cb5"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9848829.0\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 6, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r policy_19999.zip policy_19999/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgPAM1ZHN1V8",
        "outputId": "d418fcc6-5396-4290-b9c2-e492b02086cb"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: policy_19999/ (stored 0%)\n",
            "  adding: policy_19999/saved_model.pb (deflated 90%)\n",
            "  adding: policy_19999/policy_specs.pbtxt (deflated 86%)\n",
            "  adding: policy_19999/assets/ (stored 0%)\n",
            "  adding: policy_19999/variables/ (stored 0%)\n",
            "  adding: policy_19999/variables/variables.data-00000-of-00001 (deflated 9%)\n",
            "  adding: policy_19999/variables/variables.index (deflated 63%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ez4PaP32QbeG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}